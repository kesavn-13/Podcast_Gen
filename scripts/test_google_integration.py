"""
Test Google Gemini integration with existing Paper‚ÜíPodcast system
This tests the compatibility with your original architecture
"""

import os
import asyncio
import sys
from pathlib import Path

# Add project root to path
sys.path.insert(0, str(Path(__file__).parent.parent))

# Load environment variables from .env file
from dotenv import load_dotenv
load_dotenv()

# Import your existing system
from scripts.test_end_to_end import PodcastAgentOrchestrator
from backend.tools.sm_client import create_clients


async def test_google_integration():
    """Test Google Gemini integration with your existing system"""
    
    print("üß™ TESTING GOOGLE GEMINI INTEGRATION")
    print("=" * 50)
    
    # Check environment setup
    google_api_key = os.getenv("GOOGLE_API_KEY")
    if not google_api_key or google_api_key == "your-google-api-key-here":
        print("‚ùå GOOGLE_API_KEY not configured")
        print("   Please update your .env file with your actual Google API key")
        print("   Get it from: https://makersuite.google.com/app/apikey")
        return False
    
    # Set environment to use Google LLM
    os.environ['USE_GOOGLE_LLM'] = 'true'
    os.environ['USE_LOCAL_LLM'] = 'false'
    os.environ['USE_MOCK_SERVICES'] = 'false'
    
    try:
        # Test 1: Client Creation
        print("\nüì° Testing client creation...")
        reasoning_client, embedding_client = create_clients()
        print(f"‚úÖ Clients created successfully")
        print(f"   Reasoning client: {type(reasoning_client).__name__}")
        print(f"   Embedding client: {type(embedding_client).__name__}")
        
        # Test 2: Basic LLM Generation
        print("\nü§ñ Testing basic LLM generation...")
        test_messages = [
            {"role": "system", "content": "You are a helpful AI assistant."},
            {"role": "user", "content": "Explain what a transformer neural network is in one paragraph."}
        ]
        
        response = await reasoning_client.generate(test_messages)
        
        if 'choices' in response and response['choices']:
            content = response['choices'][0]['message']['content']
            print(f"‚úÖ LLM generation successful")
            print(f"   Response length: {len(content)} characters")
            print(f"   Provider: {response.get('provider', 'unknown')}")
        else:
            print("‚ùå LLM generation failed - no response content")
            return False
        
        # Test 3: Structured Response (Outline)
        print("\nüìù Testing structured outline generation...")
        outline_messages = [
            {
                "role": "system", 
                "content": "Generate a podcast episode outline from research paper content."
            },
            {
                "role": "user",
                "content": """
                Attention Is All You Need
                
                We propose a new simple network architecture, the Transformer, based solely on attention mechanisms, 
                dispensing with recurrence and convolutions entirely. Experiments on two machine translation tasks 
                show these models to be superior in quality while being more parallelizable and requiring 
                significantly less time to train.
                """
            }
        ]
        
        outline_response = await reasoning_client.generate(outline_messages, response_type="outline")
        
        if 'choices' in outline_response:
            outline_content = outline_response['choices'][0]['message']['content']
            try:
                import json
                if isinstance(outline_content, str):
                    outline_data = json.loads(outline_content)
                else:
                    outline_data = outline_content
                
                print(f"‚úÖ Structured outline generation successful")
                print(f"   Title: {outline_data.get('title', 'N/A')}")
                print(f"   Segments: {len(outline_data.get('segments', []))}")
                
            except (json.JSONDecodeError, TypeError) as e:
                print(f"‚ö†Ô∏è  Outline structure parsing failed: {e}")
                print(f"   Raw content: {outline_content[:200]}...")
        
        # Test 4: Embedding Generation
        print("\nüîç Testing embedding generation...")
        test_texts = [
            "This is a test sentence for embedding generation.",
            "Transformers are a type of neural network architecture.",
            "Attention mechanisms allow models to focus on relevant parts of input."
        ]
        
        embed_response = await embedding_client.embed(test_texts)
        
        if 'data' in embed_response and embed_response['data']:
            embeddings = embed_response['data']
            print(f"‚úÖ Embedding generation successful")
            print(f"   Generated {len(embeddings)} embeddings")
            print(f"   Embedding dimension: {len(embeddings[0]['embedding'])}")
        else:
            print("‚ùå Embedding generation failed")
            if 'error' in embed_response:
                print(f"   Error: {embed_response['error']}")
        
        # Test 5: Integration with Full System
        print("\nüé¨ Testing integration with full podcast orchestrator...")
        orchestrator = PodcastAgentOrchestrator(use_local_llm=False)
        
        # Test with sample paper content
        test_paper_path = "samples/papers/transformer_attention.txt"
        if not Path(test_paper_path).exists():
            # Create a sample file for testing 
            Path("samples/papers").mkdir(parents=True, exist_ok=True)
            with open(test_paper_path, 'w') as f:
                f.write("""
                Attention Is All You Need
                Abstract:
                The dominant sequence transduction models are based on complex recurrent or convolutional neural networks that include an encoder and a decoder. The best performing models also connect the encoder and decoder through an attention mechanism. We propose a new simple network architecture, the Transformer, based solely on attention mechanisms, dispensing with recurrence and convolutions entirely.
                
                Introduction:
                Recurrent neural networks, long short-term memory and gated recurrent neural networks in particular, have been firmly established as state of the art approaches in sequence modeling and transduction problems such as language modeling and machine translation.
                """)
        
        try:
            # Test paper processing (just the outline generation part)
            result = await orchestrator._load_paper(test_paper_path)
            if result:
                print(f"‚úÖ Paper loading successful")
                print(f"   Title: {result.get('title', 'N/A')}")
                print(f"   Content length: {len(result.get('content', ''))}")
                
                # Test outline generation with orchestrator
                outline = await orchestrator._generate_outline("test_paper", result)
                if outline and 'segments' in outline:
                    print(f"‚úÖ Full system integration successful")
                    print(f"   Generated {len(outline['segments'])} segments")
                else:
                    print(f"‚ö†Ô∏è  Outline generation incomplete: {outline}")
            else:
                print("‚ùå Paper loading failed")
                
        except Exception as e:
            print(f"‚ö†Ô∏è  Full system test failed: {e}")
        
        print("\n" + "=" * 50)
        print("üéâ GOOGLE GEMINI INTEGRATION TEST COMPLETE!")
        print("=" * 50)
        print("‚úÖ Your existing Paper‚ÜíPodcast system now uses Google Gemini!")
        print("‚úÖ All components are compatible with the original architecture")
        print("‚úÖ Ready to generate high-quality, long-form podcasts")
        
        print("\nüöÄ Next Steps:")
        print("   1. Run full end-to-end test: python scripts/test_end_to_end.py")
        print("   2. Start the FastAPI server: python app/main.py")
        print("   3. Upload a research paper and generate your first Google-powered podcast!")
        
        return True
        
    except Exception as e:
        print(f"‚ùå Integration test failed: {e}")
        import traceback
        traceback.print_exc()
        return False


if __name__ == "__main__":
    success = asyncio.run(test_google_integration())
    if success:
        print("\nüéØ Integration successful! Google Gemini is now your primary LLM.")
    else:
        print("\nüí• Integration failed. Please check the errors above.")