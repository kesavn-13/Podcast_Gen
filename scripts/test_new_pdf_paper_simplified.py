#!/usr/bin/env python3
"""
Simplified test script for new PDF paper processing
Bypasses embeddings (quota exceeded) but uses Google Gemini for content generation
"""

import os
import sys
import asyncio
import json
import logging
import re
import time
from datetime import datetime
from pathlib import Path

# Add project root to path
sys.path.append(str(Path(__file__).parent.parent))

from dotenv import load_dotenv
load_dotenv()

from backend.tools.sm_client import create_clients
from app.audio_generator import PodcastAudioProducer
from app.styles.podcast_structure import get_podcast_structure, format_podcast_segment, should_add_ad_break

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class SimplifiedPaperTester:
    """Test workflow with NVIDIA NIMs and podcast styles"""
    
    def __init__(self, podcast_style: str = "layperson"):
        self.paper_path = "samples/papers/LightEndoStereo- A Real-time Lightweight Stereo Matching Method for Endoscopy Images.pdf"
        self.output_dir = Path("temp/new_paper_test")
        self.output_dir.mkdir(parents=True, exist_ok=True)
        
        # Store selected podcast style
        self.podcast_style = podcast_style
        
        # Check if we're in hackathon mode
        hackathon_mode = os.getenv('HACKATHON_MODE', 'false').lower() == 'true'
        use_nvidia = os.getenv('USE_NVIDIA_NIM', 'false').lower() == 'true'
        
        # Initialize clients (will automatically use NVIDIA if configured)
        self.reasoner_client, self.embedding_client = create_clients()
        
        # Show which clients we're using
        llm_type = type(self.reasoner_client).__name__
        embed_type = type(self.embedding_client).__name__
        
        if hackathon_mode and use_nvidia:
            print(f"üèÜ HACKATHON MODE: Using NVIDIA NIMs")
            print(f"   ü§ñ LLM: {llm_type}")
            print(f"   üîç Embedding: {embed_type}")
        else:
            print(f"ü§ñ Using LLM: {llm_type}, Embedding: {embed_type}")
        
        # Audio configuration flags so we can disable resource-heavy pieces on small nodes
        self.use_natural_voices = os.getenv('USE_NATURAL_VOICES', 'true').lower() == 'true'
        self.use_real_tts = os.getenv('USE_REAL_TTS', 'true').lower() == 'true'
        self.generate_audio_enabled = os.getenv('GENERATE_PODCAST_AUDIO', 'true').lower() == 'true'

        # Initialize audio producer only when audio output is enabled
        self.audio_producer = None
        if self.generate_audio_enabled:
            self.audio_producer = PodcastAudioProducer(
                use_natural_voices=self.use_natural_voices,
                podcast_style=podcast_style,
                use_real_tts=self.use_real_tts
            )
        
        print(f"üé≠ Initialized with podcast style: {podcast_style}")
        
        # Show available style features
        style_features = {
            'layperson': 'Friendly, accessible explanations for general audience',
            'classroom': 'Teacher-student dynamic with structured learning approach',
            'tech_interview': 'Technical deep dive with expert analysis and methodology focus',
            'journal_club': 'Academic peer review and critical discussion of research findings',
            'npr_calm': 'Professional, measured NPR-style presentation with thoughtful pacing',
            'news_flash': 'Fast-paced, urgent news bulletin style with breaking research updates',
            'tech_energetic': 'High-energy tech discussion with excitement about innovations',
            'debate_format': 'Opposing viewpoints with spirited disagreement and critical analysis'
        }
        
        if podcast_style in style_features:
            print(f"üìù Style features: {style_features[podcast_style]}")

        if not self.generate_audio_enabled:
            print("üîá Audio generation disabled via GENERATE_PODCAST_AUDIO=false")
        else:
            if self.use_real_tts:
                voice_note = "Google TTS + Enhanced pyttsx3" if self.use_natural_voices else "mock voice library"
                print(f"üé§ Natural voices enabled: {voice_note}")
            else:
                print("üé§ Using mock TTS pipeline (USE_REAL_TTS=false)")
            print(f"‚ú® Conversation styles integrated for human-like dialogue")

            # Show available styles when TTS is active
            try:
                from app.audio_generator import RealTTSEngine
                available_styles = RealTTSEngine.list_available_styles()
                print("üéôÔ∏è Available podcast styles:")
                for style_id, description in available_styles.items():
                    indicator = "üëâ" if style_id == podcast_style else "  "
                    print(f"   {indicator} {style_id}: {description}")
                print()
            except Exception as e:
                print(f"‚ö†Ô∏è  Could not load styles info: {e}")
                print()
        
    def _load_json_with_fixes(self, raw_json, context=""):
        """Attempt to parse JSON string while fixing common formatting issues."""
        if raw_json is None:
            return {}
        if isinstance(raw_json, dict):
            return raw_json

        if not isinstance(raw_json, str):
            return raw_json

        cleaned = raw_json.strip()

        # Normalize smart quotes and apostrophes
        replacements = {
            "‚Äú": '"',
            "‚Äù": '"',
            "‚Äô": "'",
            "\u201c": '"',
            "\u201d": '"',
        }
        for old, new in replacements.items():
            cleaned = cleaned.replace(old, new)

        # Fix keys accidentally including colon inside the quotes, e.g. "text: "
        cleaned = re.sub(r'"([A-Za-z0-9_]+)\s*:\s"', r'"\1": "', cleaned)

        # Remove trailing commas before closing braces/brackets
        cleaned = re.sub(r',\s*([}\]])', r'\1', cleaned)

        # Strip any trailing markdown fences accidentally left over
        if cleaned.startswith('```') and cleaned.endswith('```'):
            cleaned = cleaned.strip('`')

        try:
            return json.loads(cleaned)
        except json.JSONDecodeError as exc:
            preview = cleaned[:500]
            raise ValueError(f"Failed to parse JSON{f' for {context}' if context else ''}: {exc}. Preview: {preview}")

    async def extract_pdf_text(self):
        """Extract text from PDF"""
        print("\nüîç Step 1: PDF Text Extraction")
        print("=" * 50)
        
        try:
            import fitz  # PyMuPDF
            doc = fitz.open(self.paper_path)
            text = ""
            page_count = len(doc)
            for page in doc:
                text += page.get_text()
            doc.close()
            
            print(f"‚úÖ Extracted {len(text)} characters from {page_count} pages")
            
            # Save extracted text
            text_file = self.output_dir / "extracted_text.txt"
            with open(text_file, 'w', encoding='utf-8') as f:
                f.write(text)
            
            # Show preview
            preview = text[:500] + "..." if len(text) > 500 else text
            print(f"üìÑ Text preview:\n{preview}")
            
            return text
            
        except Exception as e:
            print(f"‚ùå PDF extraction error: {e}")
            return None
    
    async def generate_outline_direct(self, paper_text):
        """Generate outline directly using Google Gemini (no embeddings)"""
        print("\nüß† Step 2: Google Gemini Outline Generation (Direct)")
        print("=" * 50)
        
        try:
            # Use first 3000 characters for context
            context = paper_text[:3000]
            
            outline_prompt = f"""
            You are a podcast script writer. Create a comprehensive 6-segment podcast outline for this research paper about LightEndoStereo.
            
            Paper content: {context}
            
            Create 6 segments covering:
            1. Introduction & Problem Setup (75 seconds)
            2. Background & Related Work (150 seconds)  
            3. Methodology & Architecture (210 seconds)
            4. Experimental Results (210 seconds)
            5. Clinical Applications & Impact (150 seconds)
            6. Conclusions & Future Work (75 seconds)
            
            IMPORTANT: Respond with ONLY valid JSON. No markdown, no explanations, no code blocks. Just the raw JSON object.
            
            JSON structure:
            {{
                "title": "LightEndoStereo: Real-time Stereo Matching for Endoscopy",
                "description": "Complete analysis of lightweight stereo matching for medical endoscopy",
                "segments": [
                    {{
                        "title": "Introduction & Problem Setup",
                        "duration_seconds": 75,
                        "description": "Overview of the stereo matching problem in endoscopy"
                    }},
                    ... (continue for all 6 segments)
                ]
            }}
            """
            
            messages = [{"role": "user", "content": outline_prompt}]
            response = await self.reasoner_client.generate(messages)
            
            # Parse JSON response
            try:
                # Handle the response format from Google Gemini and NVIDIA
                if isinstance(response, dict) and 'choices' in response:
                    # Extract content from the API response format
                        content = response['choices'][0]['message']['content']
                        outline_data = self._load_json_with_fixes(content, context="outline generation (choices)")
                elif isinstance(response, dict) and 'content' in response:
                    # NVIDIA NIM format - content may be wrapped in markdown
                    content = response['content']
                    
                    # Extract JSON from markdown code blocks if present
                    if '```json' in content:
                        # Find JSON block
                        json_start = content.find('```json') + 7
                        json_end = content.find('```', json_start)
                        if json_end != -1:
                            json_content = content[json_start:json_end].strip()
                        else:
                            json_content = content[json_start:].strip()
                    elif '```' in content:
                        # Generic code block
                        json_start = content.find('```') + 3
                        json_end = content.find('```', json_start)
                        if json_end != -1:
                            json_content = content[json_start:json_end].strip()
                        else:
                            json_content = content[json_start:].strip()
                    else:
                        json_content = content
                    
                        outline_data = self._load_json_with_fixes(json_content, context="outline generation (nim content)")
                elif isinstance(response, str):
                    outline_data = self._load_json_with_fixes(response, context="outline generation (string)")
                else:
                    outline_data = response
                
                segments = outline_data.get('segments', [])
                print("‚úÖ Google Gemini outline generation successful")
                print(f"üìä Generated {len(segments)} segments")
                
                # Debug: Show the actual response
                print(f"üîç Debug - Response keys: {list(outline_data.keys())}")
                if not segments:
                    print(f"‚ö†Ô∏è  No segments found. Full response: {outline_data}")
                
                # Save outline
                outline_file = self.output_dir / "podcast_outline.json"
                with open(outline_file, 'w') as f:
                    json.dump(outline_data, f, indent=2)
                
                for i, segment in enumerate(segments, 1):
                    print(f"   {i}. {segment.get('title', 'Untitled')} ({segment.get('duration_seconds', 0)}s)")
                
                # Return outline_data even if segments is empty for debugging
                return outline_data
                
            except (json.JSONDecodeError, TypeError) as e:
                print(f"‚ùå Failed to parse JSON response: {e}")
                print(f"Raw response type: {type(response)}")
                print(f"Raw response: {str(response)[:1000]}...")
                
                # Try to extract and show the actual JSON content
                if isinstance(response, dict) and 'content' in response:
                    print(f"üìù JSON Content Length: {len(response['content'])}")
                    print(f"üìù JSON Content Preview: {response['content'][:2000]}...")
                    if len(response['content']) > 2000:
                        print(f"üìù JSON Content End: ...{response['content'][-500:]}")
                return None
                
        except Exception as e:
            print(f"‚ùå Outline generation error: {e}")
            return None
    
    async def generate_and_validate_scripts(self, outline_data, paper_text):
        """Generate scripts with proper workflow: Draft ‚Üí FactCheck ‚Üí Rewrite if needed"""
        print("\nüìù Step 3: Podcast Script Generation with FactCheck Workflow")
        print("=" * 50)
        
        try:
            segments = outline_data.get('segments', [])
            final_scripts = []
            
            # Check if we have segments
            if not segments:
                print("‚ùå No segments found in outline data")
                return None
            
            # Split paper text into sections for different segments
            text_sections = []
            section_size = len(paper_text) // len(segments)
            
            for i in range(len(segments)):
                start = i * section_size
                end = (i + 1) * section_size if i < len(segments) - 1 else len(paper_text)
                text_sections.append(paper_text[start:start+1500])  # Limit to 1500 chars per section
            
            for i, segment in enumerate(segments, 1):
                print(f"\nüé¨ Processing Segment {i}: {segment.get('title', 'Untitled')}")
                print("‚îÄ" * 40)
                
                # Use relevant text section
                context = text_sections[i-1] if i-1 < len(text_sections) else paper_text[:1500]
                
                # Step 3a: Draft Generation
                print(f"   üìù Drafting script...")
                draft_script = await self._generate_draft_script(segment, context, i)
                if not draft_script:
                    print(f"   ‚ùå Failed to generate draft for segment {i}")
                    continue
                
                # Step 3b: Fact-Check
                print(f"   üîç Fact-checking against source paper...")
                factcheck_result = await self._factcheck_script(draft_script, context, segment)
                
                # Step 3c: Rewrite if needed
                final_script = draft_script
                if factcheck_result['needs_rewrite']:
                    print(f"   ‚úèÔ∏è  Rewriting based on fact-check feedback...")
                    final_script = await self._rewrite_script(draft_script, factcheck_result['feedback'], context)
                    print(f"   ‚úÖ Script rewritten with improved accuracy")
                else:
                    print(f"   ‚úÖ Script passed fact-check (accuracy: {factcheck_result['accuracy']:.1%})")
                
                final_scripts.append({
                    'segment_id': i,
                    'title': segment.get('title', 'Untitled'),
                    'script': final_script,
                    'factcheck_score': factcheck_result['accuracy'],
                    'was_rewritten': factcheck_result['needs_rewrite']
                })
                
                # Small delay between segments
                await asyncio.sleep(1)
            
            if final_scripts:
                # Enhance scripts with podcast structure (intro, outro, ad breaks)
                enhanced_scripts = self._add_podcast_structure(final_scripts, outline_data.get('title', 'Research Discussion'))
                
                # Save all scripts with metadata
                scripts_file = self.output_dir / "podcast_scripts_factchecked.json"
                with open(scripts_file, 'w') as f:
                    json.dump(enhanced_scripts, f, indent=2)
                
                # Show summary
                total_accuracy = sum(s['factcheck_score'] for s in final_scripts) / len(final_scripts)
                rewrites = sum(1 for s in final_scripts if s['was_rewritten'])
                
                print(f"\n‚úÖ Generated {len(final_scripts)} fact-checked segments")
                print(f"üìä Average factcheck accuracy: {total_accuracy:.1%}")
                print(f"‚úèÔ∏è  Segments rewritten: {rewrites}/{len(final_scripts)}")
                print(f"üéôÔ∏è Added podcast structure elements (intro, outro, ad breaks)")
                
                return enhanced_scripts
            else:
                print("‚ùå No scripts were successfully generated")
                return None
                
        except Exception as e:
            print(f"‚ùå Script generation workflow error: {e}")
            return None

    def _add_podcast_structure(self, final_scripts, topic_title):
        """Add intro, outro, and ad breaks to create a complete podcast experience"""
        enhanced_scripts = []
        total_segments = len(final_scripts)
        
        # Extract topic name for structure elements
        topic = topic_title.replace("Research Paper:", "").strip()
        
        # Add podcast intro
        intro_text = format_podcast_segment("intro", self.podcast_style, topic)
        enhanced_scripts.append({
            'segment_id': 0,
            'title': 'Podcast Intro',
            'script': [
                {"speaker": "host1", "text": intro_text}
            ],
            'factcheck_score': 1.0,
            'was_rewritten': False,
            'structure_type': 'intro'
        })
        
        # Add main content segments with ad breaks
        for i, script_data in enumerate(final_scripts):
            enhanced_scripts.append(script_data)
            
            # Add ad break in the middle for longer episodes
            if should_add_ad_break(i + 1, total_segments):
                ad_break_text = format_podcast_segment("ad_break", self.podcast_style, topic)
                enhanced_scripts.append({
                    'segment_id': f"ad_break_{i+1}",
                    'title': 'Ad Break',
                    'script': [
                        {"speaker": "host1", "text": ad_break_text}
                    ],
                    'factcheck_score': 1.0,
                    'was_rewritten': False,
                    'structure_type': 'ad_break'
                })
        
        # Add podcast outro
        outro_text = format_podcast_segment("outro", self.podcast_style, topic)
        enhanced_scripts.append({
            'segment_id': 'outro',
            'title': 'Podcast Outro',
            'script': [
                {"speaker": "host1", "text": outro_text}
            ],
            'factcheck_score': 1.0,
            'was_rewritten': False,
            'structure_type': 'outro'
        })
        
        return enhanced_scripts
    
    async def _generate_draft_script(self, segment, context, segment_num):
        """Generate initial draft script"""
        
        # Customize prompt based on podcast style
        if self.podcast_style == "debate_format":
            script_prompt = f"""
            Create a natural debate script between Dr. Sarah (research advocate) and Dr. Alex (research skeptic) discussing this segment of the LightEndoStereo research paper.
            
            Segment: {segment.get('title', 'Untitled')}
            Description: {segment.get('description', '')}
            Target Duration: {segment.get('duration_seconds', 120)} seconds
            
            Paper Context: {context}
            
            Create a balanced debate conversation with:
            - host1 (Dr. Sarah): Generally supports the research but acknowledges valid criticism
            - host2 (Dr. Alex): More skeptical but gives credit where due
            
            CRITICAL: Make this sound like real humans having a thoughtful disagreement:
            - MORE DISAGREEMENT than agreement (85% opposition, 15% agreement)
            - Include moments where one person corrects the other's mistakes or misinterpretations
            - Sarah should sometimes misstate something that Alex corrects, and vice versa
            - Use natural correction phrases like:
              * "Wait, that's not right..."
              * "Actually, you're overlooking something important..."
              * "No, I disagree with that interpretation..."
              * "Hold on, that's not what the data shows..."
              * "Actually, I think you're wrong about that..."
            - Only agree when the point is genuinely strong and hard to dispute
            - Create substantive disagreements about methodology, conclusions, implications
            - Sound like colleagues having a spirited debate where they challenge each other's thinking
            
            IMPORTANT: Respond with ONLY valid JSON. No markdown, no explanations, no code blocks. Just the raw JSON object.
            
            JSON format:
            {{
                "script": [
                    {{"speaker": "host1", "text": "This research shows some really promising results..."}},
                    {{"speaker": "host2", "text": "I'll admit the results look good, but I'm still concerned about..."}},
                    ... (continue with natural balanced debate)
                ]
            }}
            """
        else:
            script_prompt = f"""
            Create a conversational podcast script between Dr. Sarah and Dr. Alex discussing this segment of the LightEndoStereo research paper.
            
            Segment: {segment.get('title', 'Untitled')}
            Description: {segment.get('description', '')}
            Target Duration: {segment.get('duration_seconds', 120)} seconds
            
            Paper Context: {context}
            
            Create natural conversation with:
            - host1 (Dr. Sarah): Female researcher, explains technical concepts clearly
            - host2 (Dr. Alex): Male researcher, asks clarifying questions and provides insights
            
            Make it engaging and accessible while maintaining technical accuracy.
            
            IMPORTANT: Respond with ONLY valid JSON. No markdown, no explanations, no code blocks. Just the raw JSON object.
            
            JSON format:
            {{
                "script": [
                    {{"speaker": "host1", "text": "Welcome to our discussion on LightEndoStereo..."}},
                    {{"speaker": "host2", "text": "This is fascinating research. Can you explain..."}},
                    ... (continue with natural conversation)
                ]
            }}
            """
        
        try:
            messages = [{"role": "user", "content": script_prompt}]
            response = await self.reasoner_client.generate(messages)
            
            # Handle the response format from Google Gemini and NVIDIA
            if isinstance(response, dict) and 'choices' in response:
                content = response['choices'][0]['message']['content']
                script_data = self._load_json_with_fixes(content, context=f"script draft (segment {segment_num})")
            elif isinstance(response, dict) and 'content' in response:
                # NVIDIA NIM format - content may be wrapped in markdown
                content = response['content']
                
                # Extract JSON from markdown code blocks if present
                if '```json' in content:
                    # Find JSON block
                    json_start = content.find('```json') + 7
                    json_end = content.find('```', json_start)
                    if json_end != -1:
                        json_content = content[json_start:json_end].strip()
                    else:
                        json_content = content[json_start:].strip()
                elif '```' in content:
                    # Generic code block
                    json_start = content.find('```') + 3
                    json_end = content.find('```', json_start)
                    if json_end != -1:
                        json_content = content[json_start:json_end].strip()
                    else:
                        json_content = content[json_start:].strip()
                else:
                    json_content = content
                
                # Try to fix common JSON issues before parsing
                json_content = json_content.strip()
                
                # Fix common NVIDIA JSON issues
                if json_content.startswith('```') and not json_content.startswith('```json'):
                    # Remove any remaining code blocks
                    json_content = json_content.replace('```', '').strip()
                
                # Try to extract just the JSON object if there's extra text
                if '{' in json_content and '}' in json_content:
                    start = json_content.find('{')
                    end = json_content.rfind('}') + 1
                    json_content = json_content[start:end]
                
                script_data = self._load_json_with_fixes(json_content, context=f"script draft (segment {segment_num})")
            elif isinstance(response, str):
                script_data = self._load_json_with_fixes(response, context=f"script draft (segment {segment_num})")
            else:
                script_data = response
                
            script_lines = script_data.get('script', [])
            print(f"      ‚úÖ Generated {len(script_lines)} dialogue lines")
            return script_lines
            
        except Exception as e:
            print(f"      ‚ùå Draft generation failed: {e}")
            if isinstance(response, dict) and 'content' in response:
                print(f"      üîç Raw content: {response['content'][:500]}...")
            return None
    
    async def _factcheck_script(self, script, context, segment):
        """Fact-check script against source material"""
        script_text = " ".join([line.get('text', '') for line in script])
        
        factcheck_prompt = f"""
        You are a fact-checker. Verify the accuracy of this podcast script segment against the source research paper content.
        
        Segment Topic: {segment.get('title', 'Unknown')}
        Source Paper Context: {context}
        
        Script to Check: {script_text}
        
        Analyze for:
        1. Technical accuracy
        2. Correct interpretation of research findings
        3. Appropriate representation of methodology
        4. Accurate citation of results
        
        Rate accuracy from 0.0 to 1.0 and provide feedback.
        
        IMPORTANT: Respond with ONLY valid JSON. No markdown, no explanations, no code blocks. Just the raw JSON object.
        
        JSON format:
        {{
            "accuracy": 0.85,
            "needs_rewrite": false,
            "feedback": "Script is technically accurate. Minor suggestion: clarify the 42 FPS performance metric context."
        }}
        """
        
        try:
            messages = [{"role": "user", "content": factcheck_prompt}]
            response = await self.reasoner_client.generate(messages)
            
            # Handle response format from Google Gemini and NVIDIA
            if isinstance(response, dict) and 'choices' in response:
                content = response['choices'][0]['message']['content']
                factcheck_data = self._load_json_with_fixes(content, context=f"factcheck (segment {segment.get('title', 'Unknown')})")
            elif isinstance(response, dict) and 'content' in response:
                # NVIDIA NIM format - content may be wrapped in markdown
                content = response['content']
                
                # Extract JSON from markdown code blocks if present
                if '```json' in content:
                    json_start = content.find('```json') + 7
                    json_end = content.find('```', json_start)
                    if json_end != -1:
                        json_content = content[json_start:json_end].strip()
                    else:
                        json_content = content[json_start:].strip()
                elif '```' in content:
                    json_start = content.find('```') + 3
                    json_end = content.find('```', json_start)
                    if json_end != -1:
                        json_content = content[json_start:json_end].strip()
                    else:
                        json_content = content[json_start:].strip()
                else:
                    json_content = content
                
                factcheck_data = self._load_json_with_fixes(json_content, context=f"factcheck (segment {segment.get('title', 'Unknown')})")
            elif isinstance(response, str):
                factcheck_data = self._load_json_with_fixes(response, context=f"factcheck (segment {segment.get('title', 'Unknown')})")
            else:
                factcheck_data = response
            
            accuracy = factcheck_data.get('accuracy', 0.8)
            needs_rewrite = factcheck_data.get('needs_rewrite', accuracy < 0.75)
            feedback = factcheck_data.get('feedback', 'No specific feedback provided')
            
            return {
                'accuracy': accuracy,
                'needs_rewrite': needs_rewrite,
                'feedback': feedback
            }
            
        except Exception as e:
            print(f"      ‚ö†Ô∏è  Fact-check failed, assuming acceptable: {e}")
            return {'accuracy': 0.8, 'needs_rewrite': False, 'feedback': 'Fact-check unavailable'}
    
    async def _rewrite_script(self, original_script, feedback, context):
        """Rewrite script based on fact-check feedback"""
        original_text = json.dumps(original_script, indent=2)
        
        rewrite_prompt = f"""
        Improve this podcast script based on the fact-check feedback while maintaining the conversational flow.
        
        Original Script: {original_text}
        
        Fact-check Feedback: {feedback}
        
        Source Context: {context}
        
        IMPORTANT: Respond with ONLY valid JSON. No markdown, no explanations, no code blocks. Just the raw JSON object.
        
        JSON format:
        {{
            "script": [
                {{"speaker": "host1", "text": "..."}},
                {{"speaker": "host2", "text": "..."}},
                ...
            ]
        }}
        """
        
        try:
            messages = [{"role": "user", "content": rewrite_prompt}]
            response = await self.reasoner_client.generate(messages)
            
            # Handle response format from Google Gemini and NVIDIA
            if isinstance(response, dict) and 'choices' in response:
                content = response['choices'][0]['message']['content']
                script_data = self._load_json_with_fixes(content, context="rewrite script")
            elif isinstance(response, dict) and 'content' in response:
                # NVIDIA NIM format - content may be wrapped in markdown
                content = response['content']
                
                # Extract JSON from markdown code blocks if present
                if '```json' in content:
                    json_start = content.find('```json') + 7
                    json_end = content.find('```', json_start)
                    if json_end != -1:
                        json_content = content[json_start:json_end].strip()
                    else:
                        json_content = content[json_start:].strip()
                elif '```' in content:
                    json_start = content.find('```') + 3
                    json_end = content.find('```', json_start)
                    if json_end != -1:
                        json_content = content[json_start:json_end].strip()
                    else:
                        json_content = content[json_start:].strip()
                else:
                    json_content = content
                
                script_data = self._load_json_with_fixes(json_content, context="rewrite script")
            elif isinstance(response, str):
                script_data = self._load_json_with_fixes(response, context="rewrite script")
            else:
                script_data = response
                
            return script_data.get('script', original_script)
            
        except Exception as e:
            print(f"      ‚ö†Ô∏è  Rewrite failed, using original: {e}")
            return original_script
    
    async def generate_audio(self, scripts_data):
        """Step 4: TTS Generation and Step 5: Stitching with Podcast Styles"""
        print("\nüéµ Step 4: TTS Generation & Step 5: Audio Stitching")
        print("=" * 50)
        print(f"üé≠ Using podcast style: {self.podcast_style}")
        
        try:
            if not self.generate_audio_enabled or not self.audio_producer:
                print("üîá Audio generation disabled; skipping TTS and stitching steps")
                placeholder = self.output_dir / "audio_generation_skipped.txt"
                placeholder.write_text("Audio generation skipped by configuration.\n")
                return str(placeholder)

            # Prepare episode data
            episode_data = {
                'episode_id': 'lightendostereo_test',
                'title': 'LightEndoStereo: Real-time Stereo Matching for Endoscopy',
                'description': 'A comprehensive discussion of lightweight stereo matching methods for medical endoscopy applications',
                'segments': []
            }
            
            # Convert scripts to audio format
            for script_segment in scripts_data:
                segment_data = {
                    'segment_id': script_segment['segment_id'],
                    'title': script_segment['title'],
                    'script': script_segment['script']
                }
                episode_data['segments'].append(segment_data)
            
            # Generate audio with conversation styles
            print("üé§ Starting audio generation with conversation flow...")
            
            # Preserve AI-generated speaker assignments instead of overriding them
            script_segments = []
            for segment in episode_data['segments']:
                script_dialogue = segment.get('script', [])
                
                if isinstance(script_dialogue, list) and script_dialogue:
                    # Preserve the original AI-generated speaker assignments
                    for dialogue_line in script_dialogue:
                        if isinstance(dialogue_line, dict):
                            speaker = dialogue_line.get('speaker', 'host1')
                            text = dialogue_line.get('text', '')
                            if text:
                                # Map AI speakers to our host system
                                if speaker in ['host1', 'Dr. Sarah', 'sarah']:
                                    mapped_speaker = 'host1'
                                elif speaker in ['host2', 'Dr. Alex', 'alex']:
                                    mapped_speaker = 'host2'
                                else:
                                    mapped_speaker = 'host1'  # default fallback
                                
                                script_segments.append({
                                    "text": text,
                                    "speaker": mapped_speaker
                                })
                        elif isinstance(dialogue_line, str) and dialogue_line:
                            script_segments.append({
                                "text": dialogue_line,
                                "speaker": "host1"  # fallback for string-only content
                            })
                elif isinstance(script_dialogue, str) and script_dialogue:
                    script_segments.append({
                        "text": script_dialogue,
                        "speaker": "host1"
                    })
            
            if not script_segments:
                print("‚ùå No content found for audio generation")
                return None
            
            print(f"üìù Processing {len(script_segments)} dialogue segments preserving AI speaker assignments...")
            
            # Generate audio preserving original speaker assignments with natural voices + styles
            audio_file = await self.audio_producer.generate_podcast_audio(
                script_segments=script_segments,
                episode_id=f"episode_{episode_data['episode_id']}"
            )
            
            if audio_file and os.path.exists(audio_file):
                file_size = os.path.getsize(audio_file) / (1024 * 1024)  # MB
                print(f"‚úÖ Audio generated successfully with {self.podcast_style} style!")
                print(f"üìÅ File: {audio_file}")
                print(f"üìä Size: {file_size:.2f} MB")
                
                return audio_file
            else:
                print("‚ùå Audio generation failed - no file created")
                return None
                
        except Exception as e:
            print(f"‚ùå Audio generation error: {e}")
            return None
    
    async def run_simplified_test(self):
        """Run complete workflow: Upload ‚Üí Index ‚Üí Outline ‚Üí Draft ‚Üí FactCheck ‚Üí Rewrite ‚Üí TTS ‚Üí Stitch ‚Üí Export"""
        print("üöÄ Complete PDF Paper Workflow Test: LightEndoStereo")
        print("üìã Workflow: Upload ‚Üí Index ‚Üí Outline ‚Üí Draft ‚Üí FactCheck ‚Üí Rewrite ‚Üí TTS ‚Üí Stitch ‚Üí Export")
        print("‚ö†Ô∏è  Note: Bypassing embeddings due to quota limits")
        print("=" * 70)
        print(f"üìÖ Test started: {datetime.now()}")
        
        # Step 1: Upload (PDF Text Extraction)
        print("\nüì§ Step 1: Upload")
        paper_text = await self.extract_pdf_text()
        if not paper_text:
            print("‚ùå Cannot proceed without extracted text")
            return False
        
        # Step 2: Index (Skipped due to embedding quota)
        print("\nüóÉÔ∏è  Step 2: Index")
        print("‚ö†Ô∏è  Indexing skipped due to embedding API quota limits")
        print("‚úÖ Using direct text analysis instead")
        
        # Step 3: Outline Generation
        print("\nüìã Step 3: Outline Generation")
        outline_data = await self.generate_outline_direct(paper_text)
        if not outline_data:
            print("‚ùå Cannot proceed without outline")
            return False
        
        # Steps 4-6: Draft ‚Üí FactCheck ‚Üí Rewrite (for each segment)
        scripts_data = await self.generate_and_validate_scripts(outline_data, paper_text)
        if not scripts_data:
            print("‚ùå Cannot proceed without scripts")
            return False
        
        # Steps 7-8: TTS ‚Üí Stitch
        audio_file = await self.generate_audio(scripts_data)
        
        # Step 9: Export & Final Results
        print("\nüì§ Step 9: Export & Final Results")
        print("=" * 70)
        if audio_file:
            if self.generate_audio_enabled:
                print("‚úÖ COMPLETE SUCCESS: Full workflow pipeline working!")
                print(f"üéß Generated podcast: {audio_file}")
            else:
                print("‚úÖ COMPLETE SUCCESS: Text workflow complete (audio skipped by configuration)")
                print(f"üóíÔ∏è Audio step output: {audio_file}")

            print(f"üìä All files saved to: {self.output_dir}")
            print("\nüìã Completed Workflow Steps:")
            print("   ‚úÖ Upload: PDF text extraction")
            print("   ‚ö†Ô∏è  Index: Skipped (embedding quota)")
            print("   ‚úÖ Outline: Google Gemini generation")
            print("   ‚úÖ Draft: Script generation per segment")
            print("   ‚úÖ FactCheck: Accuracy verification")
            print("   ‚úÖ Rewrite: Content improvement (if needed)")

            if self.generate_audio_enabled:
                print("   ‚úÖ TTS: Professional audio synthesis")
                print("   ‚úÖ Stitch: Episode assembly")
                print("   ‚úÖ Export: Final MP3 generation")
            else:
                print("   ‚ö†Ô∏è  TTS: Skipped (GENERATE_PODCAST_AUDIO=false)")
                print("   ‚ö†Ô∏è  Stitch: Skipped (GENERATE_PODCAST_AUDIO=false)")
                print("   ‚ö†Ô∏è  Export: Skipped (GENERATE_PODCAST_AUDIO=false)")
        else:
            print("‚ö†Ô∏è  PARTIAL SUCCESS: Workflow mostly complete, audio issues")
        
        return bool(audio_file)

async def test_multiple_styles():
    """Test the system with multiple podcast styles to showcase variety"""
    print("üé≠ COMPREHENSIVE STYLE TESTING")
    print("=" * 60)
    
    # Test all available podcast styles from macOS folder with descriptions
    test_styles = [
        ('layperson', 'Friendly, accessible explanations for general audience'),
        ('classroom', 'Teacher-student dynamic with structured learning approach'),
        ('tech_interview', 'Technical deep dive with expert analysis and methodology focus'),
        ('journal_club', 'Academic peer review and critical discussion of research findings'),
        ('npr_calm', 'Professional, measured NPR-style presentation with thoughtful pacing'),
        ('news_flash', 'Fast-paced, urgent news bulletin style with breaking research updates'),
        ('tech_energetic', 'High-energy tech discussion with excitement about innovations'),
        ('debate_format', 'Opposing viewpoints with spirited disagreement and critical analysis')
    ]
    
    results = {}
    
    for style_name, style_description in test_styles:
        print(f"\nüé≠ Testing Style: {style_name.upper()}")
        print(f"üìù Description: {style_description}")
        print("-" * 60)
        
        try:
            tester = SimplifiedPaperTester(podcast_style=style_name)
            success = await tester.run_simplified_test()
            results[style_name] = success
            
            if success:
                print(f"‚úÖ {style_name} style: SUCCESSFUL")
            else:
                print(f"‚ùå {style_name} style: FAILED")
                
        except Exception as e:
            print(f"‚ùå {style_name} style error: {e}")
            results[style_name] = False
    
    # Summary
    print("\nüéØ STYLE TESTING SUMMARY")
    print("=" * 40)
    successful_styles = [style for style, success in results.items() if success]
    failed_styles = [style for style, success in results.items() if not success]
    
    print(f"‚úÖ Successful styles ({len(successful_styles)}/{len(test_styles)}):")
    for style in successful_styles:
        # Find description for this style
        style_desc = next((desc for name, desc in test_styles if name == style), "")
        print(f"   ‚úì {style}: {style_desc}")
    
    if failed_styles:
        print(f"‚ùå Failed styles ({len(failed_styles)}/{len(test_styles)}):")
        for style in failed_styles:
            style_desc = next((desc for name, desc in test_styles if name == style), "")
            print(f"   ‚úó {style}: {style_desc}")
    
    if len(successful_styles) == len(test_styles):
        print(f"\nüéâ ALL {len(test_styles)} PODCAST STYLES WORKING PERFECTLY!")
        print("üèÜ Complete NVIDIA NIM integration with full style variety!")
    else:
        print(f"\n‚ö†Ô∏è  ISSUES: {len(failed_styles)} styles need attention")
    
    return len(successful_styles) > 0

async def main():
    """Main test function with podcast style selection and NVIDIA integration"""
    import argparse
    
    # Parse command line arguments for style selection
    parser = argparse.ArgumentParser(description='Test PDF paper processing with NVIDIA NIMs and podcast styles')
    parser.add_argument('--style', 
                       choices=['layperson', 'classroom', 'tech_interview', 'journal_club', 'npr_calm', 'news_flash', 'tech_energetic', 'debate_format'],
                       default='layperson',
                       help='Choose podcast conversation style (default: layperson)')
    parser.add_argument('--test-multiple', 
                       action='store_true',
                       help='Test multiple podcast styles to showcase variety')
    parser.add_argument('--nvidia-only',
                       action='store_true', 
                       help='Force use of NVIDIA NIMs only (hackathon mode)')
    
    # Parse known args (ignore unknown ones for compatibility)
    args, _ = parser.parse_known_args()
    
    # Set hackathon environment if requested
    if args.nvidia_only:
        print("üèÜ NVIDIA-ONLY MODE: Using NVIDIA Llama + Embedding NIMs")
        os.environ['HACKATHON_MODE'] = 'true'
        os.environ['USE_NVIDIA_NIM'] = 'true'
        os.environ['USE_GOOGLE_LLM'] = 'false'
    
    try:
        if args.test_multiple:
            print("ÔøΩ TESTING MULTIPLE PODCAST STYLES WITH NVIDIA INTEGRATION")
            success = await test_multiple_styles()
        else:
            print(f"ÔøΩüéôÔ∏è Selected podcast style: {args.style}")
            if args.nvidia_only:
                print("üèÜ Using NVIDIA Llama-3.1-Nemotron-Nano-8B-v1 + nv-embedqa-e5-v5")
            
            tester = SimplifiedPaperTester(podcast_style=args.style)
            success = await tester.run_simplified_test()
        
        if success:
            print("\nüéâ SUCCESS: Your PDF paper pipeline is working with podcast styles!")
            if not args.test_multiple:
                print(f"üé≠ Used conversation style: {args.style}")
            if args.nvidia_only:
                print("üèÜ NVIDIA NIMs integration: WORKING")
            print("\nüí° Available style options:")
            print("   --style layperson (friendly, accessible)")
            print("   --style debate_format (opposing viewpoints)")
            print("   --style tech_interview (technical deep dive)")
            print("   --style journal_club (academic discussion)")
            print("   --test-multiple (test 3 different styles)")
            print("   --nvidia-only (force NVIDIA NIMs only)")
        else:
            print("\n‚ö†Ô∏è  ISSUES: Some components need attention")
            
        return success
        
    except Exception as e:
        print(f"‚ùå Test execution error: {e}")
        import traceback
        traceback.print_exc()
        return False

if __name__ == "__main__":
    result = asyncio.run(main())
    sys.exit(0 if result else 1)