"""
Paper‚ÜíPodcast: Complete Working FastAPI Backend
Simplified version for immediate testing and demo
"""

import os
import asyncio
from pathlib import Path
from typing import Dict, Any, List, Optional, Tuple
import json
import logging
from datetime import datetime
from io import BytesIO
from uuid import uuid4

try:
    from fastapi import FastAPI, HTTPException, UploadFile, File, Form, Request
    from fastapi.middleware.cors import CORSMiddleware
    from fastapi.responses import FileResponse, JSONResponse, HTMLResponse
    from fastapi.staticfiles import StaticFiles
    from fastapi.templating import Jinja2Templates
    from pydantic import BaseModel
    FASTAPI_AVAILABLE = True
except ImportError:
    FASTAPI_AVAILABLE = False
    print("‚ö†Ô∏è  FastAPI not installed. Run: pip install fastapi uvicorn")

# Add project root to path
import sys
sys.path.insert(0, str(Path(__file__).parent.parent))

if FASTAPI_AVAILABLE:
    # In-memory job tracking
    jobs: Dict[str, Dict[str, Any]] = {}

    def _utc_now() -> str:
        """Return current UTC timestamp in ISO-8601 format."""
        return datetime.utcnow().isoformat() + "Z"

    def _append_job_message(job: Dict[str, Any], message: str, level: str = "info") -> None:
        """Record a status update for a running job."""
        job.setdefault("messages", []).append({
            "timestamp": _utc_now(),
            "message": message,
            "level": level
        })

    def _ensure_directory(path: Path) -> None:
        """Create directory if it does not exist."""
        path.mkdir(parents=True, exist_ok=True)

    def _create_transcript_file(
        paper_id: str,
        job_id: str,
        title: str,
        outline: Dict[str, Any],
        segments: List[Dict[str, Any]],
    ) -> Optional[str]:
        """Serialize the generated dialogue into a transcript file."""
        if not segments:
            return None

        transcripts_dir = Path("temp/audio/episodes")
        _ensure_directory(transcripts_dir)

        transcript_path = transcripts_dir / f"{paper_id}_{job_id}_transcript.txt"
        try:
            with transcript_path.open("w", encoding="utf-8") as f:
                f.write(f"{title}\n")
                f.write(f"Generated by Paper‚ÜíPodcast Agentic Pipeline\n\n")

                if outline:
                    episode_title = outline.get("episode_title")
                    if episode_title:
                        f.write(f"Episode: {episode_title}\n\n")

                for segment in segments:
                    seg_title = segment.get("title", "Segment")
                    f.write(f"## {seg_title}\n")
                    for line in segment.get("script", []):
                        speaker = line.get("speaker", "host").upper()
                        text = line.get("text", "")
                        f.write(f"{speaker}: {text}\n")
                    f.write("\n")
            return str(transcript_path)
        except Exception as exc:
            logger.error("Failed to write transcript: %s", exc)
            return None

    def _create_report_file(
        paper_id: str,
        job_id: str,
        title: str,
        style: str,
        duration: str,
        outline: Dict[str, Any],
        segments: List[Dict[str, Any]],
        audio_path: Optional[str],
        transcript_path: Optional[str]
    ) -> Optional[str]:
        """Produce a JSON processing report for the generated episode."""
        reports_dir = Path("temp/audio/episodes")
        _ensure_directory(reports_dir)

        report_payload = {
            "job_id": job_id,
            "paper_id": paper_id,
            "title": title,
            "style": style,
            "duration_request": duration,
            "status": "completed",
            "generated_at": _utc_now(),
            "outline": outline,
            "segment_count": len(segments),
            "audio_path": audio_path,
            "transcript_path": transcript_path,
            "factuality_score": None,
        }

        factuality = _calculate_factuality_score(segments)
        if factuality is not None:
            report_payload["factuality_score"] = factuality

        for idx, segment in enumerate(segments, start=1):
            summary = {
                "title": segment.get("title"),
                "duration": segment.get("duration"),
                "factcheck_score": segment.get("factcheck", {}).get("factcheck_score"),
                "audio_path": segment.get("audio_path"),
            }
            report_payload.setdefault("segments", []).append(summary)

        report_path = reports_dir / f"{paper_id}_{job_id}_report.json"
        try:
            report_path.write_text(json.dumps(report_payload, indent=2), encoding="utf-8")
            return str(report_path)
        except Exception as exc:
            logger.error("Failed to write processing report: %s", exc)
            return None

    def _calculate_factuality_score(segments: List[Dict[str, Any]]) -> Optional[float]:
        """Compute average fact-check score from segment metadata."""
        scores: List[float] = []
        for segment in segments:
            factcheck = segment.get("factcheck", {}) if isinstance(segment, dict) else {}
            score = factcheck.get("factcheck_score")
            if isinstance(score, (int, float)):
                scores.append(float(score))
            elif isinstance(score, str):
                try:
                    scores.append(float(score))
                except ValueError:
                    continue
        if not scores:
            return None
        return sum(scores) / len(scores)

    async def _run_job(
        job_id: str,
        paper_id: str,
        saved_path: Path,
        title: str,
        style: str,
        duration: str,
    ) -> None:
        """Execute the simplified workflow and update job progress."""
        job = jobs.get(job_id)
        if job is None:
            return

        job["status"] = "processing"
        job["started_at"] = _utc_now()
        job.setdefault("progress", 0)
        job.setdefault("outputs", {})

        if SimplifiedPaperTester is None:
            job["status"] = "failed"
            job["error"] = "Simplified workflow unavailable"
            _append_job_message(job, "Simplified workflow unavailable", "error")
            return

        try:
            style_choice = style or "layperson"
            job_output_dir = Path("temp/jobs") / job_id

            tester = SimplifiedPaperTester(
                podcast_style=style_choice,
                paper_path=str(saved_path),
                output_dir=str(job_output_dir)
            )

            _append_job_message(job, "Extracting paper text")
            job["progress"] = 10
            paper_text = await tester.extract_pdf_text()
            if not paper_text:
                raise RuntimeError("Failed to extract text from uploaded paper")

            _append_job_message(job, "Generating outline with NVIDIA NIM")
            job["progress"] = 30
            outline_data = await tester.generate_outline_direct(paper_text)
            if not outline_data:
                raise RuntimeError("Outline generation returned no data")

            _append_job_message(job, "Drafting and fact-checking segments")
            job["progress"] = 55
            scripts_data = await tester.generate_and_validate_scripts(outline_data, paper_text)
            if not scripts_data:
                raise RuntimeError("Script generation failed")

            _append_job_message(job, "Rendering podcast audio")
            job["progress"] = 75
            episode_audio = await tester.generate_audio(scripts_data)
            if not episode_audio or not os.path.exists(episode_audio):
                raise RuntimeError("Audio generation failed")

            job["progress"] = 90

            segments: List[Dict[str, Any]] = []
            for idx, segment in enumerate(tester.last_scripts or scripts_data, start=1):
                factcheck_score = segment.get("factcheck_score")
                factcheck_feedback = segment.get("factcheck_feedback")
                segments.append({
                    "segment_num": segment.get("segment_id", idx),
                    "title": segment.get("title"),
                    "script": segment.get("script", []),
                    "factcheck": {
                        "factcheck_score": factcheck_score,
                        "feedback": factcheck_feedback,
                        "needs_rewrite": segment.get("was_rewritten", False),
                    },
                    "structure_type": segment.get("structure_type"),
                    "duration": segment.get("duration_seconds"),
                    "audio_path": None,
                })

            outline = tester.last_outline or outline_data or {}
            factuality_score = _calculate_factuality_score(segments)

            transcript_path = _create_transcript_file(paper_id, job_id, title, outline, segments)
            report_path = _create_report_file(
                paper_id,
                job_id,
                title,
                style_choice,
                duration,
                outline,
                segments,
                episode_audio,
                transcript_path,
            )

            job["outputs"].update(
                {
                    key: value
                    for key, value in {
                        "audio": episode_audio,
                        "transcript": transcript_path,
                        "report": report_path,
                    }.items()
                    if value
                }
            )

            job["status"] = "completed"
            job["progress"] = 100
            job["completed_at"] = _utc_now()
            job["factuality_score"] = factuality_score
            job["result"] = {
                "paper_id": paper_id,
                "title": title,
                "outline": outline,
                "segments": segments,
                "audio_path": episode_audio,
                "transcript_path": transcript_path,
                "report_path": report_path,
                "factuality_score": factuality_score,
            }
            _append_job_message(job, "Podcast generation complete", "success")
        except Exception as exc:  # pragma: no cover - runtime guard
            logger.exception("Job %s failed", job_id)
            job["status"] = "failed"
            job["error"] = str(exc)
            _append_job_message(job, f"Job failed: {exc}", "error")
    try:
        from scripts.test_new_pdf_paper_simplified import SimplifiedPaperTester
    except ImportError:
        print("‚ö†Ô∏è  Could not import SimplifiedPaperTester")
        SimplifiedPaperTester = None

try:
    from PyPDF2 import PdfReader
except ImportError:
    PdfReader = None


# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Global orchestrator instance (unused in simplified workflow)
orchestrator = None
workflow_ready = False
DEFAULT_PODCAST_STYLE = os.getenv("DEFAULT_PODCAST_STYLE", "layperson")

if FASTAPI_AVAILABLE:
    # Request/Response models
    class PaperUploadResponse(BaseModel):
        paper_id: str
        title: str
        status: str
        message: str

    class SegmentRequest(BaseModel):
        segment_index: int
        
    # FastAPI app initialization
    app = FastAPI(
        title="Paper‚ÜíPodcast: Agentic + Verified",
        description="üèÜ AWS & NVIDIA Hackathon Submission - Transform research papers into verified podcast episodes",
        version="1.0.0"
    )

    # Add CORS middleware
    app.add_middleware(
        CORSMiddleware,
        allow_origins=["*"],
        allow_credentials=True,
        allow_methods=["*"],
        allow_headers=["*"],
    )

    templates = Jinja2Templates(directory=str(Path(__file__).parent / "templates"))

    static_dir = Path(__file__).parent / "static"
    if static_dir.exists():
        app.mount("/static", StaticFiles(directory=str(static_dir)), name="static")

    def _extract_text_from_upload(filename: str, raw_bytes: bytes) -> str:
        """Convert uploaded content to UTF-8 text, with PDF support."""

        if not raw_bytes:
            raise HTTPException(status_code=400, detail="Uploaded file is empty")

        lower_name = (filename or "").lower()
        if lower_name.endswith(".pdf") or lower_name.endswith(".x-pdf") or lower_name.endswith(".pdfx"):
            if PdfReader is None:
                raise HTTPException(status_code=500, detail="PDF support not installed. Install PyPDF2.")
            try:
                reader = PdfReader(BytesIO(raw_bytes))
                pages = [(page.extract_text() or "") for page in reader.pages]
                text = "\n".join(pages).strip()
                if not text:
                    raise ValueError("No text extracted from PDF")
                return text
            except Exception as exc:  # pragma: no cover - depends on PDF contents
                logger.error("PDF extraction failed: %s", exc)
                raise HTTPException(status_code=400, detail="Unable to extract text from the provided PDF")

        try:
            return raw_bytes.decode("utf-8", errors="ignore")
        except Exception as exc:  # pragma: no cover - unexpected encodings
            logger.error("Text decode failed: %s", exc)
            raise HTTPException(status_code=400, detail="Unable to decode uploaded file as text")

    async def _persist_upload(upload: UploadFile) -> Tuple[str, Path, str]:
        """Save the uploaded file to disk and return metadata."""

        content = await upload.read()
        text_content = _extract_text_from_upload(upload.filename or "document", content)

        paper_id = f"paper_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
        file_path = Path("temp/uploads") / f"{paper_id}.txt"
        file_path.parent.mkdir(parents=True, exist_ok=True)
        file_path.write_text(text_content, encoding="utf-8")

        title = text_content.splitlines()[0][:100] if text_content else (upload.filename or paper_id)
        logger.info("üìÑ Uploaded paper saved: %s - %s", paper_id, title)
        return paper_id, file_path, title

    @app.on_event("startup")
    async def startup_event():
        """Initialize the system on startup"""
        global workflow_ready

        workflow_ready = SimplifiedPaperTester is not None
        if workflow_ready:
            logger.info("üé≠ Simplified workflow ready (default style: %s)", DEFAULT_PODCAST_STYLE)
        else:
            logger.warning("‚ö†Ô∏è  Simplified Paper Tester not available; workflow endpoints disabled")

        for directory in [
            Path("temp/uploads"),
            Path("temp/audio"),
            Path("temp/audio/episodes"),
            Path("temp/audio/segments"),
            Path("temp/jobs"),
        ]:
            _ensure_directory(directory)

    @app.get("/")
    async def root():
        """API root endpoint"""
        return {
            "message": "Paper‚ÜíPodcast Agentic API", 
            "version": "1.0.0",
            "status": "ready",
            "hackathon": "AWS & NVIDIA Agentic AI Unleashed",
            "mode": "local_llm" if os.getenv("USE_LOCAL_LLM", "false").lower() == "true" else "mock",
            "workflow": "available" if workflow_ready else "unavailable",
            "endpoints": {
                "upload": "/upload",
                "index": "/index/{paper_id}",
                "outline": "/outline/{paper_id}",
                "segment": "/segment/{paper_id}",
                "factcheck": "/factcheck/{paper_id}",
                "tts": "/tts/{paper_id}",
                "stitch": "/stitch/{paper_id}",
                "report": "/report/{paper_id}",
                "docs": "/docs"
            }
        }

    @app.get("/health")
    async def health_check():
        """Health check endpoint"""
        return {
            "status": "healthy",
            "timestamp": datetime.now().isoformat(),
            "mode": "local_llm" if os.getenv("USE_LOCAL_LLM", "false").lower() == "true" else "mock",
            "workflow": "available" if workflow_ready else "unavailable"
        }

    @app.get("/ready")
    async def readiness_check():
        """Readiness endpoint for Kubernetes probes.

        Reports ready when the app is initialized and the orchestrator is available.
        """
        ready = workflow_ready
        status = "ready" if ready else "initializing"
        return {
            "status": status,
            "workflow": "available" if ready else "unavailable",
            "timestamp": datetime.now().isoformat(),
        }

    @app.get("/ui", response_class=HTMLResponse)
    async def serve_ui(request: Request):
        """Serve the interactive web UI template."""
        return templates.TemplateResponse("index.html", {"request": request})

    @app.post("/upload", response_model=PaperUploadResponse)
    async def upload_paper(file: UploadFile = File(...)):
        """Upload and store a research paper for later processing."""
        try:
            paper_id, _, title = await _persist_upload(file)
            return PaperUploadResponse(
                paper_id=paper_id,
                title=title,
                status="uploaded",
                message="Paper uploaded successfully"
            )
        except HTTPException:
            raise
        except Exception as exc:  # pragma: no cover - unexpected errors
            logger.error("Upload failed: %s", exc)
            raise HTTPException(status_code=500, detail=str(exc))

    @app.post("/agentic-workflow")
    async def agentic_workflow(
        file: UploadFile = File(...),
        style: str = Form("conversational"),
        duration: str = Form("medium")
    ):
        """Queue a new paper‚Üípodcast job and process it asynchronously."""

        if not workflow_ready or SimplifiedPaperTester is None:
            raise HTTPException(status_code=503, detail="Simplified workflow not available")

        paper_id, saved_path, title = await _persist_upload(file)

        job_id = str(uuid4())
        job_entry = {
            "job_id": job_id,
            "paper_id": paper_id,
            "title": title,
            "style": style,
            "duration": duration,
            "status": "queued",
            "progress": 0,
            "created_at": _utc_now(),
            "messages": [],
            "outputs": {},
        }

        jobs[job_id] = job_entry
        _append_job_message(job_entry, "Job queued for processing")

        # Launch async workflow without blocking the request cycle
        asyncio.create_task(_run_job(job_id, paper_id, saved_path, title, style, duration))

        return {
            "job_id": job_id,
            "paper_id": paper_id,
            "title": title,
            "status": job_entry["status"],
            "progress": job_entry["progress"],
        }

    @app.get("/status/{job_id}")
    async def get_job_status(job_id: str):
        """Expose the current state of a running or completed job."""
        job = jobs.get(job_id)
        if not job:
            raise HTTPException(status_code=404, detail="Job not found")

        result = job.get("result") or {}
        segments = result.get("segments") or []

        return {
            "job_id": job_id,
            "paper_id": job.get("paper_id"),
            "title": job.get("title"),
            "status": job.get("status", "unknown"),
            "progress": job.get("progress", 0),
            "style": job.get("style"),
            "duration": job.get("duration"),
            "created_at": job.get("created_at"),
            "started_at": job.get("started_at"),
            "completed_at": job.get("completed_at"),
            "messages": job.get("messages", []),
            "outputs": job.get("outputs", {}),
            "error": job.get("error"),
            "segment_count": len(segments),
            "factuality_score": job.get("factuality_score"),
        }

    @app.get("/download/{job_id}/{artifact}")
    async def download_artifact(job_id: str, artifact: str):
        """Download generated assets for a completed job."""
        job = jobs.get(job_id)
        if not job:
            raise HTTPException(status_code=404, detail="Job not found")

        if job.get("status") != "completed":
            raise HTTPException(status_code=409, detail="Job not completed yet")

        outputs = job.get("outputs", {})
        path_str = outputs.get(artifact)
        if not path_str:
            raise HTTPException(status_code=404, detail="Requested artifact unavailable")

        file_path = Path(path_str)
        if not file_path.exists():
            raise HTTPException(status_code=404, detail="Artifact file missing on server")

        media_type_map = {
            "audio": "audio/mpeg",
            "transcript": "text/plain",
            "report": "application/json",
        }
        media_type = media_type_map.get(artifact, "application/octet-stream")

        return FileResponse(
            path=file_path,
            filename=file_path.name,
            media_type=media_type,
        )

    @app.post("/index/{paper_id}")
    async def index_paper(paper_id: str):
        """Index paper for RAG retrieval"""
        try:
            paper_path = Path(f"temp/uploads/{paper_id}.txt")
            if not paper_path.exists():
                raise HTTPException(status_code=404, detail="Paper not found")
            
            if not orchestrator:
                return {"status": "mock_indexed", "paper_id": paper_id, "message": "Mock indexing (orchestrator unavailable)"}
            
            # Load and index paper
            with open(paper_path, 'r', encoding='utf-8', errors='ignore') as f:
                content = f.read()
            
            title = content.split('\n')[0] if content else paper_id
            
            success = await orchestrator.retrieval.index_paper(
                paper_id=paper_id,
                content=content,
                title=title
            )
            
            if success:
                return {"status": "indexed", "paper_id": paper_id, "message": "Paper indexed successfully"}
            else:
                raise HTTPException(status_code=500, detail="Indexing failed")
                
        except Exception as e:
            logger.error(f"‚ùå Indexing failed: {e}")
            raise HTTPException(status_code=500, detail=str(e))

    @app.get("/outline/{paper_id}")
    async def generate_outline(paper_id: str):
        """Generate podcast episode outline"""
        try:
            paper_path = Path(f"temp/uploads/{paper_id}.txt")
            if not paper_path.exists():
                raise HTTPException(status_code=404, detail="Paper not found")
            
            if not orchestrator:
                # Return mock outline
                return {
                    "paper_id": paper_id,
                    "episode_title": f"Episode: Research Paper {paper_id}",
                    "target_duration_minutes": 15,
                    "segments": [
                        {"title": "Introduction", "target_duration": 180, "key_points": ["Paper overview"]},
                        {"title": "Methodology", "target_duration": 240, "key_points": ["Research approach"]},
                        {"title": "Results", "target_duration": 240, "key_points": ["Key findings"]},
                        {"title": "Conclusion", "target_duration": 180, "key_points": ["Implications"]}
                    ]
                }
            
            # Load paper content
            with open(paper_path, 'r', encoding='utf-8', errors='ignore') as f:
                content = f.read()
            
            paper_content = {
                "title": content.split('\n')[0] if content else paper_id,
                "content": content
            }
            
            # Generate outline
            outline = await orchestrator._generate_outline(paper_id, paper_content)
            
            return {
                "paper_id": paper_id,
                "episode_title": outline.get("episode_title", f"Episode: {paper_content['title']}"),
                "target_duration_minutes": outline.get("target_duration_minutes", 15),
                "segments": outline.get("segments", [])
            }
            
        except Exception as e:
            logger.error(f"‚ùå Outline generation failed: {e}")
            raise HTTPException(status_code=500, detail=str(e))

    @app.post("/segment/{paper_id}")
    async def generate_segment(paper_id: str, request: SegmentRequest):
        """Generate script for a specific segment"""
        try:
            if not orchestrator:
                # Return mock segment
                return {
                    "segment_index": request.segment_index,
                    "title": f"Segment {request.segment_index}",
                    "script_lines": [
                        {"speaker": "host1", "text": f"Welcome to segment {request.segment_index} of our discussion."},
                        {"speaker": "host2", "text": "This is a fascinating topic with important implications."},
                        {"speaker": "host1", "text": "The research methodology here is particularly innovative."},
                        {"speaker": "host2", "text": "And the results show significant advances in the field."}
                    ],
                    "citations": ["p.1", "p.3"],
                    "estimated_duration_s": 180
                }
            
            # For demo, create a simple segment info
            segment_info = {
                "title": f"Segment {request.segment_index}",
                "key_points": ["research methodology", "key findings"],
                "target_duration": 180
            }
            
            # Generate segment script
            script = await orchestrator._generate_segment_script(paper_id, request.segment_index, segment_info)
            
            # Extract citations from script
            citations = []
            for line in script:
                if "[Source" in line['text']:
                    citations.extend([cite.strip() for cite in line['text'].split('[Source') if ']' in cite])
            
            return {
                "segment_index": request.segment_index,
                "title": segment_info["title"],
                "script_lines": script,
                "citations": list(set(citations)),
                "estimated_duration_s": segment_info["target_duration"]
            }
            
        except Exception as e:
            logger.error(f"‚ùå Segment generation failed: {e}")
            raise HTTPException(status_code=500, detail=str(e))

    @app.get("/papers")
    async def list_papers():
        """List available papers"""
        upload_dir = Path("temp/uploads")
        papers = []
        
        if upload_dir.exists():
            for paper_file in upload_dir.glob("*.txt"):
                papers.append({
                    "paper_id": paper_file.stem,
                    "filename": paper_file.name,
                    "uploaded": paper_file.stat().st_mtime
                })
        
        return {"papers": papers}

    @app.get("/demo")
    async def demo_endpoint():
        """Demo endpoint for quick testing"""
        return {
            "message": "Paper‚ÜíPodcast Demo Ready!",
            "test_workflow": [
                "1. POST /upload (upload a text file)",
                "2. POST /index/{paper_id} (index for RAG)",  
                "3. GET /outline/{paper_id} (generate outline)",
                "4. POST /segment/{paper_id} (generate segment)",
                "5. GET /papers (list all papers)"
            ],
            "hackathon_features": {
                "agentic_workflow": "‚úÖ Multi-agent collaboration",
                "nvidia_nim": "‚úÖ llama-3.1-nemotron-nano-8B-v1 + Retrieval NIM",
                "aws_ready": "‚úÖ SageMaker + OpenSearch deployment",
                "fact_checking": "‚úÖ RAG-based verification",
                "audio_generation": "‚úÖ Podcast TTS pipeline"
            }
        }

else:
    # Fallback when FastAPI is not available
    def create_app():
        print("‚ùå FastAPI not available. Install with: pip install fastapi uvicorn")
        return None
    
    app = create_app()

# Main entry point
def main():
    """Main entry point for running the server"""
    if not FASTAPI_AVAILABLE:
        print("‚ùå Cannot start server: FastAPI not installed")
        print("   Install with: pip install fastapi uvicorn")
        return
    
    try:
        import uvicorn
        
        # Get configuration from environment
        host = os.getenv("API_HOST", "0.0.0.0")
        port = int(os.getenv("API_PORT", 8000))
        
        print(f"üöÄ Starting Paper‚ÜíPodcast API on http://{host}:{port}")
        print("üìö API Documentation: http://localhost:8000/docs")
        print("üéØ Demo endpoint: http://localhost:8000/demo")
        
        uvicorn.run(app, host=host, port=port, reload=True)
        
    except ImportError:
        print("‚ùå uvicorn not installed. Run: pip install uvicorn")
    except Exception as e:
        print(f"‚ùå Server startup failed: {e}")

if __name__ == "__main__":
    main()